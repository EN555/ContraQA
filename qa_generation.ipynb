{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b6ab947-c7d6-4deb-bb61-2434d815c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "\n",
    "api_key = \"\"\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff459e7-b5c0-44ba-ae32-68cb80d5fcb6",
   "metadata": {},
   "source": [
    "# Only neutral instanecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "367777c8-c51e-4fc6-a6cf-f738a1aa0bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"raw_data/healthver_climate-fever_all_neutral.json\", 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "186abd9a-8186-4354-b5b4-70a325195a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:20<00:00, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Finished updating instances with generated questions!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI  # make sure your OpenAI client is installed and set up\n",
    "\n",
    "\n",
    "# ========== PROMPTS ==========\n",
    "\n",
    "prompt_qa = \"\"\"Given a claim, your task is to:\n",
    "Read the claim carefully.\n",
    "\n",
    "Generate two questions based on the claim that refer to information mentioned or implied in it:\n",
    "\n",
    "- One WH-question.\n",
    "- One Yes/No question.\n",
    "\n",
    "Additionally:\n",
    "- Try to focus on specific elements or details from the claim that could naturally invite questions.\n",
    "\n",
    "For the WH-question, classify it as one of the following two types:\n",
    "- Function Question – A question with a single definitive answer (e.g., “What is the capital of France?”).\n",
    "- List Question – A question that may have multiple valid answers (e.g., “What causes air pollution?”).\n",
    "\n",
    "Your response must follow the exact JSON format shown below:\n",
    "{\n",
    "  \"wh_question\": \"<Your WH-question here>\",\n",
    "  \"question_type\": \"<Function Question or List Question>\",\n",
    "  \"yes_no_question\": \"<Your Yes/No question here>\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "prompt_verification = \"\"\"You are given an evidence sentence and a question.\n",
    "\n",
    "Task: Determine whether the evidence provides an answer to the question.\n",
    "\n",
    "Evidence:\n",
    "\\\"\\\"\\\"{evidence}\\\"\\\"\\\"\n",
    "\n",
    "Question:\n",
    "\\\"\\\"\\\"{question}\\\"\\\"\\\"\n",
    "\n",
    "Instructions:\n",
    "- If the evidence answers the question, respond only with \"Yes\".\n",
    "- If the evidence does not answer the question, respond only with \"No\".\n",
    "- Do not explain your answer. Just output \"Yes\" or \"No\".\n",
    "\"\"\"\n",
    "\n",
    "# ========== FUNCTIONS ==========\n",
    "\n",
    "def get_gpt_response(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    content = content.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "    return content\n",
    "\n",
    "def generate_questions(claim):\n",
    "    combined_prompt = f\"{prompt_qa}\\n\\nClaim:\\n{claim}\\n\"\n",
    "    raw_output = get_gpt_response(combined_prompt)\n",
    "    try:\n",
    "        return json.loads(raw_output)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Failed to decode JSON from:\", raw_output)\n",
    "        return None\n",
    "\n",
    "def check_evidence_answers_question(evidence, question):\n",
    "    verification_prompt = prompt_verification.format(evidence=evidence, question=question)\n",
    "    response = get_gpt_response(verification_prompt)\n",
    "    return response.strip()\n",
    "\n",
    "# ========== MAIN PROCESS ==========\n",
    "\n",
    "# Load your input data\n",
    "with open(\"raw_data/healthver_climate-fever_all_neutral.json\", 'r', encoding='utf-8') as f:\n",
    "    instances = json.load(f)\n",
    "\n",
    "for instance in tqdm(instances[:2]):  # Only first 2 for testing\n",
    "    claim = instance['claim']\n",
    "    evidences = instance['evidences']\n",
    "    \n",
    "    # Phase 1: Generate questions based only on the claim\n",
    "    questions = generate_questions(claim)\n",
    "    if questions is None:\n",
    "        instance['generated_questions'] = {}\n",
    "        continue  # No questions generated\n",
    "\n",
    "    valid_questions = {}\n",
    "\n",
    "    # Phase 2: Check WH-question\n",
    "    wh_is_answered = False\n",
    "    for evidence in evidences:\n",
    "        wh_answered = check_evidence_answers_question(evidence, questions['wh_question'])\n",
    "        if wh_answered.lower() == \"yes\":\n",
    "            wh_is_answered = True\n",
    "            break\n",
    "\n",
    "    if not wh_is_answered:\n",
    "        valid_questions[\"wh_question\"] = questions[\"wh_question\"]\n",
    "        valid_questions[\"question_type\"] = questions[\"question_type\"]\n",
    "\n",
    "    # Phase 3: Check Yes/No question\n",
    "    yesno_is_answered = False\n",
    "    for evidence in evidences:\n",
    "        yesno_answered = check_evidence_answers_question(evidence, questions['yes_no_question'])\n",
    "        if yesno_answered.lower() == \"yes\":\n",
    "            yesno_is_answered = True\n",
    "            break\n",
    "\n",
    "    if not yesno_is_answered:\n",
    "        valid_questions[\"yes_no_question\"] = questions[\"yes_no_question\"]\n",
    "\n",
    "    # Add valid generated questions to the instance\n",
    "    instance['generated_questions'] = valid_questions\n",
    "\n",
    "# Save all results (original data + new field)\n",
    "with open(\"raw_data/healthver_climate-fever_all_neutral_with_questions.json\", \"w\", encoding='utf-8') as f_out:\n",
    "    json.dump(instances, f_out, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ Finished updating instances with generated questions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3a3a1d-ffb9-4ffc-8576-5a40fd1d7525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
